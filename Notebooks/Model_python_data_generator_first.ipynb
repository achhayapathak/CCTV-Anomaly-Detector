{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RlF0suUp1_hi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665253956332,"user_tz":-330,"elapsed":28686,"user":{"displayName":"Kunal Pant","userId":"17699106600863430817"}},"outputId":"76992428-54df-4fca-f706-9ccbcac295d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#Mount the drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["#Import required libraries\n","\n","import cv2\n","import os\n","import copy\n","import pandas as pd\n","import numpy as np\n","import matplotlib as plt\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from keras.utils import np_utils\n","%matplotlib inline "],"metadata":{"id":"H5QxR2PY2Kjv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Temporal Length - corresponds to the number of continuous frames you want to have in a single sample.\n","\n","Temporal Stride - Number of frames that you want to skip b/w two samples\n","\n","Yield Keyword: https://www.geeksforgeeks.org/python-yield-keyword/"],"metadata":{"id":"DsCStn6h7GDp"}},{"cell_type":"code","source":["#Function to yield a single sample.\n","\n","def file_generator(data_path,data_files,temporal_stride=1,temporal_length=16):\n","\n","    #data files contains list of all the csv \n","\n","\n","    # read all the csv files (one csv file corresponds to one vdieo) in data_files one by one\n","\n","    for f in data_files: \n","\n","      #f corresponds to a particular csv (containing path of frames of that particular video)\n","\n","        tmp_df = pd.read_csv(os.path.join(data_path,f))\n","        \n","        #Get the label for this video/csv\n","        label_list = list(tmp_df['Label'])  \n","        \n","        #Total number of frames in this video\n","        total_images = len(label_list) \n","\n","        if total_images>=temporal_length: \n","           #If the number of frames in the video is greater tha temporal length, use that video\n","            num_samples = int((total_images-temporal_length)/temporal_stride)+1\n","            print ('num of samples from vid seq-{}: {}'.format(f,num_samples))\n","            img_list = list(tmp_df['FileName'])\n","\n","        else:\n","            #If total number of frames is less than temporal length than skip this video \n","            print ('num of frames is less than temporal length; hence discarding this file-{}'.format(f))\n","            continue\n","\n","        start_frame = 0\n","        #Initliaze a queue to store the frames\n","        samples = deque()  \n","\n","        #A counter to count the number of samples. one sample has as many frames as defined by temporal length\n","        samp_count=0 \n","        for img in img_list:\n","            samples.append(img)\n","            if len(samples)==temporal_length: #if the queue has as many frames as temporal length, return it as one sample\n","                samples_c=copy.deepcopy(samples) # copy the queue as in the next stage frames would be popped\n","                samp_count+=1\n","                \n","                #Pop out as many frames as described by the stride from the left to accomodate new frames\n","                for t in range(temporal_stride): \n","                    samples.popleft()\n","                yield samples_c,label_list[0]\n","        \n","                # return a sample(consisting of as many frames as defined by temporal length) \n","                                                # and its corsponding label "],"metadata":{"id":"MCvFKuvi4E9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the samples and their corresponding label for each video\n","\n","def load_samples(data_cat='train',temporal_stride=1,temporal_length=16):\n","\n","    #data_cat= cahnge according to your folder names\n","\n","    #Path to folder containing csvs (Either test or train)\n","    data_path = os.path.join('data_files',data_cat)\n","\n","    #List of CSVs\n","    data_files = os.listdir(data_path)\n","\n","    # define a generator to read the samples\n","    file_gen = file_generator(data_path,data_files,temporal_stride,temporal_length)\n","    iterator = True\n","    data_list = []\n","\n","    while iterator:\n","\n","        try:\n","            x,y = next(file_gen)\n","            x=list(x)\n","            data_list.append([x,y])\n","\n","        except Exception as e:\n","            print ('the exception: ',e)\n","            iterator = False\n","            print ('end of data generator')\n","    return data_list"],"metadata":{"id":"nrf5kMKk3lSt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function to shuffle data\n","def shuffle_data(samples):\n","    data = shuffle(samples,random_state=2)\n","    return data"],"metadata":{"id":"-lhZLaSc-ae7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Change according to requirements\n","def preprocess_image(img):\n","    img = cv2.resize(img,(224,224))\n","    img = img/255\n","    return img"],"metadata":{"id":"jhUddp---yF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creates generator to be fed to the architecture.\n","\n","def data_generator(data,batch_size=16,temporal_padding='same',shuffle=True):              \n","  \n","    # Yields the next training batch.\n","    # data is an array [[img1_filename,img2_filename...,img16_filename],label1], [image2_filename,label2],...].\n","   \n","    #Total number of samples in your data\n","    num_samples = len(data)\n","\n","    if shuffle:\n","        data = shuffle_data(data)\n","\n","    while True:\n","\n","        for offset in range(0, num_samples, batch_size):\n","            print ('Starting index: ', offset) \n","\n","            # Get the samples you'll use in this batch\n","            batch_samples = data[offset:offset+batch_size]\n","\n","            # Initialise X_train and y_train arrays for this batch\n","            X_train = []\n","            y_train = []\n","            # For each example\n","\n","            # Loop over every baprint ('Total number of train samples:',len(train_data))tch\n","            for batch_sample in batch_samples: \n","                # Load image (X)\n","\n","                #x is address of frame\n","                x = batch_sample[0]\n","\n","                #y is the label\n","                y = batch_sample[1]\n","\n","                temp_data_list = []\n","\n","                for img in x:\n","                    try:\n","                        img = cv2.imread(img)\n","                        #apply any kind of preprocessing here\n","                        #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","                        img = preprocess_image(img)\n","                        temp_data_list.append(img)\n","\n","                    except Exception as e:\n","                        print (e)\n","                        print ('error reading file: ',img)\n","\n","                # Read label (y)\n","                # Append this sample to your batch\n","                X_train.append(temp_data_list)\n","                y_train.append(y)\n","    \n","            # Make sure they're numpy arrays (as opposed to lists)\n","            X_train = np.array(X_train)\n","            #X_train = np.rollaxis(X_train,1,4)\n","            y_train = np.array(y_train)\n","\n","            # # convert to one hot encoding for training keras model\n","            # y_train = np_utils.to_categorical(y_train, 3)\n","    \n","            # yield the next training batch            \n","            yield X_train, y_train\n"],"metadata":{"id":"mnd3oY3w_IWc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load the training data.**"],"metadata":{"id":"HMXsw4EjB_sN"}},{"cell_type":"code","source":["train_data = load_samples(data_cat='train',temporal_stride=4,temporal_length=16)"],"metadata":{"id":"b-FnXYI6BoPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print ('Total number of train samples:',len(train_data))"],"metadata":{"id":"QO-GMfXaB7gz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load the testing data.**"],"metadata":{"id":"rKIspffgCDDA"}},{"cell_type":"code","source":["test_data = load_samples(data_cat='test',temporal_stride=4, temporal_length=16)"],"metadata":{"id":"tXDQ-SCIBfst"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = data_generator(train_data,batch_size=4,shuffle=True)"],"metadata":{"id":"cSIP5ZUkBzDJ"},"execution_count":null,"outputs":[]}]}